分布式锁
 
redis

setnx key value ex 10
过期时间和设置锁要原子性操作

setnx 存在单点故障、主从问题
所以引出了redlock
没有主的集群，过半通过即加锁成功

redLock也有缺点：已经被加过锁的机器被重启了，那么就可能让这个redis被其他线程重新加锁
解决这个问题的办法：延迟启动，如24小时再重启

另外，单点的redis，除了单点故障，还有一个问题
JVM先给redis加了锁，并设置了过期时间
然后JVM STW了，在STW这段时间，redis的锁过期了，然后又来了一个线程，重新给redis加了锁
而此时，当JVM STW结束后，执行业务逻辑就会存在问题了 

这种问题的处理，一般的处理方案，是不处理他，鸵鸟算法
当然，还有比较成熟的解决方案，就是结合mysql+version
详细做法就是：
当JVM 给redis加锁成功后，再往mysql中写一条数据，会有一个version，比如为A0
当其他JVM做了同样的操作后，重新写一个version,为A1
那么这是时候，A0操作数据的时候，就肯定是版本号不对，那么就会操作失败
这样，就能保证数据的一致性

mysql加锁的缺点：
虽然容易理解但是实现起来较为繁琐，需要自己考虑锁超时，加事务等等。
性能局限于数据库，一般对比缓存来说性能较低。对于高并发的场景并不是很适合。


zk实现分布式锁的问题
1. zk提交类似于一个2PC过程，设置锁的性能会低于redis
2. zk leader一旦挂掉，设置锁就不可用（相对而言redis多个master节点都可以写）
3. 状态处理不正确，容易出现多个客户端持有锁或者释放不掉
因为需要频繁的创建和删除节点，性能上不如Redis方式。


分布式事务

处理方式一：协调者+两阶段提交

分布式事务的控制核心，就是中间协调者和两阶段提交
多个服务，协调者控制事务的提交，当多个服务处理好数据后，均给协调者投票
投票完成，协调者给每个服务发送提交的命令，然后每个服务在提交自己的事务

如果在提交的过程中，出现了失败的情况，就需要人工补偿，可以对失败的信息进行拦截，写程序做补偿，比如定时任务
中间协调者，一般可以是seata


这种处理方式存在的问题：
1、单点故障：如果协调者挂了，就整个挂了

2、占用资源：因为第一阶段只是执行了sql，但是没有提交，数据库链接的资源并没有释放，数据库的链接资源是有限的，如果此时没有资源了，就会出现其他
服务连不上数据库的情况

3、数据不一致：提交执行失败，可能导致数据不一致的情况，就需要人工做补偿


两阶段解决方案的扩展：
两阶段提交的协调者的中间件，有两种，LCN和seataAT

他们的区别：
LCN:会占用数据库链接资源
seataAT:不占用数据库链接资源

seataAT之所以不占用链接资源，是因为在第一阶段的时候，就直接提交了事务，所以就直接释放了资源
之所以能这么做，是因为seataAT做好了镜像记录beforeImage(修改前镜像) afterImage(修改后镜像)，seataAT的镜像数据存在与他自己的undo_log表中，
如果需要回滚，那么就直接回滚镜像就可以了，处理完成后，就会删除这两个镜像

但是也是因为seataAT的这种操作，seataAT会存在脏写问题
seataAT对应脏写问题的控制，使用全局锁。就是需要修改数据，就需要拿到全局锁
但是这种方式，是阻止不了人工手动修改的
所以这个问题的处理方式，通常就是人工修改


相对于两阶段，还有一个三阶段

三阶段，主要分为三个部分
can commit
pre commit
do commit
这个里面有个核心点，就是do commit,默认是提交的，因为前面经过了两次校验，最后是就默认提交了
同时，三阶段中，相对于两阶段，是两阶段中只有协调者存在超时的设置，参与者则没有超时的设置

为什么要有三阶段提交呢？
两阶段中，由于参与者没有超时的设置，因为当协调者挂了以后，参与者会一致等待


分布式事务一致性的保障，以及分布式事务遇到高并发时的保障
提高并发，大部分都是通过牺牲一定的一致性来解决的，同时尽量减少与磁盘的IO

常用的做法就是：
请求到对应服务器之后，然后将需要后续服务处理的信息，推送至消息中间中，后续服务通过消费消息中间件中的消息的方式，完成后续相关信息的处理，
然后，服务器只需要操作一次自己的DB，就可以响应返回。

在具体一点，就是当请求到对应服务器之后，将消息推送至消息中间件（注意，此处的消息中间件，并不一定就是MQ，也有可能是自己
实现的一个web服务+定时任务构成的服务），此时的消息还是待确认的状态，当消息中间件返回ack之后，服务器再操作对应DB，进行数据处理，此时，只执行sql,不提交，然后推送消息
确认给消息中间件，消息中间件收到确认后，执行相关任务，并返回ack给服务器，消息确认后，再提交/回滚事务
最后，还有一个定时任务，需要定时去清理消息中间件中，待确认/待取消的消息，判断当前消息是需要确认还是取消，然后将其返回给服务器，这就是整个回查的步骤。 


这个就是高并发下，分布式事务常用的解决方案。

整体逻辑就是：
1.调用创建消息接口，返回消息信息
2.操作本地库
3.确认或取消消息
4.回查

分布式事务
刚性事务：实时一致
柔性事务：最终一致性
>![avatar](/Users/liufuwei/Documents/my-project/my-juc/JUC/myJuc/image/分布式事务.png)

根据这张图，对整体流程再串一下
串之前，先说一下这个解决方案解决的问题是：高并发下，分布式事务会影响效率
1、一个请求到服务器之后，现将需要操作的信息，通过消息的方式，推送到我们的消息服务（web服务+定时任务）
2、消息服务接收到消息之后，返回确认，表明已经接收到了对应的消息，此时，消息的状态为待确认
3、服务器接收到消息服务器的确认消息后，就表明可以操作自己的数据库进行数据处理了，但此时的事务还不会提交
4、服务器对数据库操作完毕后，会再调用消息服务器，推送已经操作完DB
5、消息服务器第二次接收到服务器的请求，返回消息确认，确认消息是确认执行还是取消，此时，消息的状态变更为已确认/已取消，但未发送
6、服务器接收到消息确认后，再进行事务提交或者回滚，然后服务器返回给客户端
7、在这个过程当中，会有一个定时任务，定时去清理消息服务器中的待确认/待取消的消息，并将消息返回给消息服务器，避免消息服务器长时间处于等待状态
这个过程也叫做回查
注意，回查消息，为了更快，可以优化为查redis
处理完上诉步骤后，将继续进行后续的步骤
8、消息服务器将消息推送到MQ
9、MQ接收到消息后，返回ACK，此时，消息的状态变更为已发送
10、后续的服务订阅MQ,消费MQ中的消息，完成对对应DB的操作
11、后续服务完成操作后，返回ack给MQ，并且，后续服务，调用消息服务器，返回已完成消息处理
12、在这里，为了保证数据的一致性和可靠性，可以开启第二次的回查，通过查询业务表中的消息id,进行数据确认，若存在异常，则回滚或删除数据


这种方式和seata的方式相比，区别就是：
可支撑的并发量大
但是方案设计复杂
数据一致性比seata他们更强

注意，这个方案，适用的场景是：并发量大，需要快速响应，数据不要求强一致性的场景

处理这种场景，还有第二种方案：
>![avatar](/Users/liufuwei/Documents/my-project/my-juc/JUC/myJuc/image/分布式事务2.png)

第二种解决方案，相较于第一种，要简单得多
结合上图进行讲解
1、请求过来以后，我们直接将数据存储在我们的事件表中，存储成功后，就可以返回了，这样的处理效率更高
2、接着，我们的定时任务，定时去处理存储在事件表中，需要被处理的消息，推送至MQ
3、其他服务订阅MQ，接收到MQ消息后，也将消息存入其对应的事件表中，然后通过定时任务去进行相关业务处理
当然，当请求进来以后，也可以直接推送至MQ，这里还记录到事件表中原因，是为了记录整理过程，记录更加详细的信息，方便后续出现问题做业务排查。




网关限流技巧
限流主要是在两个部分，一部分是网关，另一部分，就是我们的服务
简单而言，就是限流需要考虑两个地方，一个公共出口，另一个就是每个小服务的出口
那么怎么做限流？
一、令牌桶算法
具体实现方法：
一个令牌生成器，以恒定的速率往令牌桶中放令牌，比如10s/个，假设令牌桶能够放置的令牌只有10个，那么令牌生成器生成的令牌超过的令牌，
就直接丢弃
然后，用户请求数据时，先到令牌桶中获取令牌，获取到了，就正常执行后续的业务逻辑，没有获取到，就拒绝这次请求
注意，是拿不到就走，或者持续等待，就看你前面的具体处理了


关于分布式事务：
用MQ来保证分布式事务，一定是建立在本地事务表基础上的，并且最终一致性，如果MQ不支持事务消息，比如Kafka，那么就用定时
任务来处理，否则就不需要定时任务。

 


