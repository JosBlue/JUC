zookeeper介绍、安装、shell cli 使用

1、回顾redis

2、zookeeper是什么？
zookeeper就是做一个分布式协调服务
分布式锁只是zookeeper中冰山一角

zookeeper数据存储在内存中，这一点与redis一样

对于zk的服务，是一个主从复制模型，有对应的主，增删改操作发生在主上，查询发生在从上
客户端连接zk的服务是不受限制的，"主"可查和写，但是"从"只能查

既然zk有主，是单点的话，就可能会挂，而zk本身就是高扩展，高性能，且是高可用性的，那么他的高可用性是怎么保证的呢？
在redis中是通过哨兵机制来保证HA的
那么回到zk，既然zk有leader,那么就可能会挂，主挂了，就会造成服务不可用，服务不可用那么这个集群就不是可靠的集群，但是事实是，zk集群是及其高可用且高性能的
设想，如果有一种方式，当leader挂了以后，可以快速恢复出一个leader，那么就可以保证高可用

另外，我们通过分析可以得出zk集群有两种状态：
可用状态： leader正常
不可用状态：leader挂了，此时就是无主状态 
那么需要做的，就是从不可用状态恢复到可用状态，就需要越快越好，才能保证高可用，那么这种恢复速度到底需要多快呢？
根据官方的压测数据，每秒4到5W个请求，主挂了之后，恢复的速度，在200ms以内，并且恢复之后，能够在开始处理请求时，恢复到更高的一个吞吐量；见图：zk可靠性

另外，随着zk服务的增多，随着读写请求中的读的占比不断提高，根据zk官方的压测数据显示，当读请求达到100%时，13个节点的zk服务，每秒可以处理大约12W到14W次的请求，即使只有3个节点的zk server，
也可以达到每秒处理8到9W的读请求，见图：zk性能

3、zookeeper的结构

zk是一个目录树结构，目录树上有很多节点（node），这些node可以存储数据，但是限制了，最多存储的数据是1MB，这些节点又可以分为持久节点和临时节点

注意，千万不要把zk当作数据库用！！！
zk自身也限定了，每个节点存储的数据不超过1M，那么为什么要做这个限制呢？
是因为zk主要用于做分布式协调，他需要做到由不可用状态到可用状态的快速切换，同时也需要保持一个更高性能。那么这个快，潜台词就是要节点上需要传输的各种数据体量尽可能得更小。
如果我们在zk的节点上存储太多数据，表面上看来是可以做到很好的分布式协调，因为当我们的某些服务挂了之后，可以将一些关键信息存储到zk的节点上，比如将数据的偏移量这些数据存储到zk的节点上，
然后当服务宕机重启后，便可以快速恢复相关的相关的数据。
但是，这样做，会增大zk节点的读写中的写的占比，导致读的占比下降，数据传输所带来的受网络带宽等的时延等的影响，就会影响到他的性能。

对于临时节点及其作用：
只要在zk中，可以创建一个临时节点znode，只要创建的临时节点的会话处于活跃状态，那么这个临时节点就会存在，当会话结束时，这个临时节点znode就会被删除。
对于这个临时节点，当你想要实现分布式锁时，就会变得很方便。
通过临时节点加锁，当临时节点的会话消失时，那么这个锁就被释放了，因为这个临时节点已经不存在了。这个时候，就不需要像使用redis创建分布式锁一样，还需要使用多线程来进行控制锁的过期时间这些。

在临时节点和持久节点中，还支持序列化，就是序列节点，但是这个序列节点并不是一个实际的节点，要么是临时节点，要么是持久节点，他们可以支持序列化，带序列号，并不是说序列节点是一个实际的节点


4、zookeeper的优势（保证/特点）：
zk非常快速而且非常简单，但是，由于其目标是构建更加复杂服务（如同步）的基础，因此，zk提供了一系列保障： 
（1）顺序一致性
客户端的发送到zk的请求，将按照发送请求的到达的先后顺序，依次顺序执行。那么这个顺序执行是怎么实现的呢？
这是由于zk采用的是比较简单的主从复制模型，当客户端发送到zk的请求到达时，对于写的请求，都需要到主节点上进行同步和处理，这也是单个主节点多带来的好处，虽然单主节点有一些单点相关的问题，
但是对于要求需要顺序处理这种需求时，一个主节点就可以更加从容的来处理排序，序列化这些问题，从而保证顺序性。
因此，简单而言，zk可以承诺可以保证顺序性，就是通过它的主从模型来保证的。


（2）原子性
所有节点，更新要么同时成功，要么同时失败，没有中间状态。可以理解为同数据库的原子性
增加一个新节点这种请求，主节点通知到所有节点，当所有节点均同意创建新节点后，这个节点才能创建成功，所以它可以保证原子性。
但是，如果需要所有节点均同意后才创建，那么这个就有点类似于强一致性了，
强一致性就必然会带来可用性上的损失，因此，在zk中，和redis一致，只要保证超过一半的节点同意了，就可以创建成功，因此，zk实际上是最终一致性。  

（3）单一系统映像
无论连接到哪个zk服务，客户端看到的都是相同的服务视图
这是由于zk的模型是复制模型，因此连到哪个服务，都看到的是一致的服务视图。


（4）可靠性
由于zk是基于内存的，既然涉及到了内存，那么就必然要涉及到持久化，不然无法保证可靠性。
zk通过写日志的方式，来保证可靠性 

（5）及时性
系统的客户端视图保证在特定时间范围内是最新的。
实际上就是zk的最终一致性。

5、zk的简单使用（通过实操，来验证上面说的）
在这个使用的过程中，主要需要关注的，就是zk两种状态的切换，是怎么做的，即从不可用状态切换到可以状态，是怎么做的

redis保证高可用，是使用哨兵机制来实现的，哨兵通过发现的方式，可以知道哪些节点是主，哪些节点是从，哨兵与哨兵之间可以知道彼此是否为哨兵，然后通过投票，统计过半数量的方式，选出新的主节点，
这是一种通过发现的机制，来实现的主从切换，保证高可用的方式

那么zk是怎么实现的呢？
首先，需要在zk的配置文件下：xx.config人为手动配置信息：
server.1=node01:2888:3888
server.2=node02:2888:3888
server.3=node03:2888:3888
server.4=node04:2888:3888

咱们详细看看这个配置文件：
在redis中，是通过发现的方式，可以知道哨兵还有哪些，主从有哪些，但是在zk中不行，需要人为将zk有哪些服务配置出来
配置出来后，也可以知道，过半就是对应配置信息的行数除以2加1，就是过半的数量
根据配置，可以知道，有4个节点，node01到node04

2888与3888这两个端口号有什么作用？
3888这个端口，是当服务初始启动时，或者当leader挂掉时，节点与节点之间，通过3888这个端口号进行通信和投票，选出主节点。===》选主投票用
当主节点重新被选举出来后，主节点启动2888这个端口，后续的节点写操作，便通过2888这个端口进行通信 ===》 leader接受write请求 

端口号这个明白后，可以看到，server前，还有数字，1到4，这个可以理解为是id
(实际的id，通过配置文件:myid进行配置）
在zk中，对于主节点的选举，是通过"谦让"选举出来的，当主节点挂掉以后，就会让id最大的，作为新的主节点（实际上不止这一个id,还有一个事务id,后续会详细说） 
有了这个思路以后，当我们启动集群时，1，2，3，4，那么谁会是主节点？
注意，我们前面说过，只要节点数过半，那么就可以选举出主节点。
我们一共4个节点，如果先启动1，2，3，由于节点数已经过半，那么其中节点id最大的就可以当主节点了，那么此时的主节点就是3，4即使启动好了，3也仍旧是主节点。
只有当3这个主节点挂掉以后，那么4才会因为id值最大，被重新推举为主节点
同样的道理，如果我们先启动2，3，4，那么4就会被推举为主节点。
因此，对于1，2，3，4谁会是主节点这个问题，有可能是3节点，也有可能是4节点。

配置完配置文件后，将zk的bin目录下的可执行文件，配置到Path目录下，便可进行后续步骤了

接下来，我们启动zk
zkServer.sh start(后台启动)
zkServer.sh start-foreground(前台启动，所有信息，都会在前台打印，方便测试和观察)
注意：如果顺序启动服务，在前期服务中，会看到一些报错，提示链接不上配置信息中的其他服务，这种表现是正常的，因为其他服务还未启动。
当启动服务节点达到3台时，满足服务过半的要求，此时可以选举出对应的leader。
后续启动的服务id即使是比当前服务的id更大，也只能是foller,除非是当前leader挂掉以后，id最大的服务才会被选举为新的leader。当存在leader后，后续启动的服务，在启动时，都会基于leader的信息
更新到自己的服务中，从而保证数据的一致性。

这里顺便说一句，zk集群服务第一次启动是最简单的。随着服务对外提供的时间流逝，在某一天，如果集群断电后重启，此时首先需要看的是哪台服务的数据最完整，如果存在多个服务的数据完整度一致，再比较他们
的id大小，从而选举出新的leader

命令：
创建节点：
create /ooxx "hello" （注意，创建空是，""也是必不可少的）
创建的节点，对应的信息，是二进制安全的。 
通过get /ooxx可以查看信息

我们简单看一下信息的内容：
"hello"
cZxid = ox200000002
ctime = Mon Sep 16 21:22:38 CST 2021
mZxid = ox200000004
mtime =  Mon Sep 16 21:22:38 CST 2021
pZxid = ox200000003
cversion = 1
dataVersion = 1
aclVersion = 0
ephemeralOwner = Ox0
...

此处仅展示了部分信息，对重要的字段进行解释说明：
"hello"：这个为我们设置的值，这个值是二进制安全的，这个数据最多只能放1M
cZxid：表示创建时的事务id，64字节，后32位，表示事务的递增序列；前32位，则表示leader的纪元，即你是第几个leader
我们根据获取到的数据：ox200000002，进行分析，0x：为16进制；2：表示这个产生的第二个leader；00000002：每一位表示4个2进制位，2位表示8个二进制位，一共4位，则4*8=32个二进制位。

mZxid：表示修改时的事务id，在操作过程中，创建了ooxx后，中间又创建了一个子目录/ooxx/xxoo；并且又修改了/ooxx的的值为"hello"，这几次操作，事务id递增上涨，因此zk中所有增删改的发生，事务
id都是按照序号递增排列 

pZxid：表示当前节点下，创建最后的节点的事务id，注意是创建的事务id,不是修改的事务id

ephemeralOwner：表示临时节点归属
现在的值为：OxO；是因为当时创建/ooxx这个节点时，并没有将当前归属为谁，即创建的为一个持久节点，即我客户端退出后再进入，这个/ooxx节点仍旧是存在的

我们输入help:
可以看到有一条命令：create [-s] [-e]  path data acl
可以看到，create时，有两个选项，一个是-s,一个是-e
当一个客户端链接zk服务时，就会创建一个sessionID，假设为Ox46d3a3992750002
然后，我们执行命令，创建一个临时节点：create -e /xoxo "123wdf"
获取节点信息：get /xoxo；此时输出的信息中，我们仅看：ephemeralOwner的数据，可以看到数值信息为：
ephemeralOwner：Ox46d3a3992750002
也就是说，当前这个临时节点的id就是当前会话的id

我们启动一个新的会话，只要之前启动的会话还未关闭，也可以看到这个临时节点的信息，并且这个临时节点id是等于之前的会话id,这个也就是统一视图

如果我们将之前的会话给退出，那么这个临时节点就不存在了，在当前新的会话中也就无法查询到/oxox这个节点了，这也是统一视图的原因

注意：我们创建会话、退出会话，都需要走统一视图，都会消耗事务id.

临时节点，是与session绑定的，且session也是要消耗事务id，统一视图的


下面我们看另外一个问题：
假设，我们创建一个目录：cretate /aaa ""
接着有很多客户端，都想往/aaa这个文件下写信息，在分布式的场景下，就可能会出现一个问题，就是覆盖，那么如何规避这个问题呢？此时就需要用到另一种创建的方式了
create -s /aaa/xxx "213" (-s:表示序列的意思)；
创建成功后，返回值为：Create /aaa/xxx00000000
可以看到，在加上-s创建成功后，在返回值的创建信息中，xxx后拼了一些信息00000000

如果我们在另一个客户端中，也创建同样的信息：create -s /aaa/xxx "243";
创建成功，返回值为：Create /aaa/xxx00000001
可以看到这个返回值后面追加的信息是递增的
这个递增的信息，也是leader在控制递增的，通过这种方式，就可以规避分布式下的覆盖问题，同时也支撑起了另一个特征，就是分布式命名
即使将001删掉后，新创建的，也是从002开始的，不会有命令重复覆盖的问题

总结，通过zk的目录树结构可以做哪些事情呢？
根据zk的目录的特性，可以做：
1.统一配置管理：所有的客户端只要记住节点的path，记住其对应的事务id,这个节点中就有对应的1M的数据，所有客户端都可以通过这个路径和id去更新这个信息，其他客户端拿到的就是最新的更新信息
2.分组管理：通过path结构，即父子目录支撑
3.统一命名：通过序列（-s）sequential支撑 
4.分布式同步：通过临时节点实现

分布式同步这个特性，进阶后，就可以做一些事情：
分布式锁（通过临时节点创建）

再进阶，如果这个锁依托一个父节点，且具备-s，那么就代表了这个父节点下可以有多把锁，既然可以带多把锁。
由于这个锁的事务id是有序的，如果后一把锁盯着前一把锁，那么就形成了一个队列，就可以做分布式事务的控制了，前一个成功后，后面在执行，就可以做事务锁了 

上述说的这些，都是需要在客户端做控制的

那么下面我们继续根据zk的特性，进行进阶，基于这些特性，还可以做：
基于分布式锁，可以做HA,选主。即谁抢到了锁，谁就是主






 
 

